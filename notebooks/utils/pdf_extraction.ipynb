{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains.openai_functions import create_structured_output_runnable\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from pypdf import PdfReader\n",
    "import openai\n",
    "import glob\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from langchain.chains.openai_functions import (\n",
    "    create_openai_fn_chain,\n",
    "    create_structured_output_chain,\n",
    "    create_openai_fn_runnable,\n",
    "    create_structured_output_runnable,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# %load_ext dotenv\n",
    "# %dotenv ./.env\n",
    "config = load_dotenv('.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read(startPage, endPage):\n",
    "    global text\n",
    "    text = []\n",
    "    cleanText = \"\"\n",
    "    pdfFileObj = open('../pdfs/textbooks/deeplearningbook_2.pdf', 'rb')\n",
    "    pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "    while startPage <= endPage:\n",
    "        pageObj = pdfReader.pages[startPage]\n",
    "        text += pageObj.extract_text()\n",
    "        startPage += 1\n",
    "    pdfFileObj.close()\n",
    "    for myWord in text:\n",
    "        if myWord != '\\n':\n",
    "            cleanText += myWord\n",
    "    text = cleanText.split()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Read(14,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text(filename):\n",
    "    file = open(filename, 'rb')\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    text = ''\n",
    "    for page in range(len(reader.pages)):\n",
    "        page = reader.pages[page]\n",
    "        text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text_from_dir(dir):\n",
    "    text = ''\n",
    "    for filename in glob.glob(os.path.join(dir, '*.pdf')):\n",
    "        text += extract_pdf_text(filename) + '\\n\\n\\n\\n\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dir = '../pdfs/textbooks'\n",
    "text = extract_pdf_text_from_dir(pdf_dir)\n",
    "with open('../data/text/text_books.txt', 'w') as f:\n",
    "    f.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_dir = '../data/pdfs/textbooks'\n",
    "# text_dir = '../output/textbooks'\n",
    "# for filename in glob.glob(os.path.join(pdf_dir, '*.pdf')):\n",
    "#     text_name = filename.split('/')[-1].split('.')[0]\n",
    "#     if ' ' in text_name:\n",
    "#         text_name = text_name.replace(' ', '_')\n",
    "#     output_name = os.path.join(text_dir, '.pdf')\n",
    "#     # dataset = create_dataset(\n",
    "#     #     model=model_name,\n",
    "#     #     tokenizer=model_name,\n",
    "#     #     file_path=filename,\n",
    "#     #     output_path=outout_file_path,\n",
    "#     #     load_in_4bit=True\n",
    "#     # )\n",
    "#     with open(output_name, 'w') as f:\n",
    "#       f.write(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = extract_pdf_text('../data/pdfs/exam.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.2, openai_api_key=OPENAI_API_KEY, model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question(BaseModel):\n",
    "    \"\"\" An Exam question \"\"\"\n",
    "    question_id: int = Field(..., description=\"The question id\")\n",
    "    qustion_type: str = Field(..., description=\"The type of question, e.g. multiple choice, short answer, long answer\")\n",
    "    question: str = Field(..., description=\"The question text\")\n",
    "    choices: list[str] = Field(..., description=\"The choices for the question\")\n",
    "    answer: str = Field(..., description=\"The answer to the question\")\n",
    "    topic: str = Field(..., description=\"The topic of the question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Questions(BaseModel):\n",
    "    \"\"\" A collection of questions \"\"\"\n",
    "    questions: list[Question] = Field(..., description=\"The questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"\"\"{\n",
    "    \"properties\": {\n",
    "        \"question_id\": {\"type\": \"string\"},\n",
    "        \"question\": {\"type\": \"string\"},\n",
    "        \"choices\": {\"type\": \"array\", \"option\": {\"type\": \"string\"}},\n",
    "        \"answer\": {\"type\": \"string\"},\n",
    "        \"question_type\": {\"type\": \"string\"},\n",
    "        \"topic\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"question_id\", \"question\", \"answer\", \"question_type\"]\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_question_answer_data(doc, llm):\n",
    "    # input = prompt.format_prompt(exam_text=doc, schema=schema)\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a world class algorithm for extracting questions and answers from exams, and putting them in a structured format.\",\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Use the following exam text to extract the questions and answers. \\n\\n {exam_text}\",\n",
    "            ),\n",
    "            (\n",
    "                \"human\", \"Tip:  Make sure to include the question id, question, answer, and question type in the output. Also make sure to use the correct format\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    chain = create_structured_output_chain(Questions, llm, prompt, verbose=True)\n",
    "    extract = chain.run(doc)\n",
    "    return extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = extract_question_answer_data(text, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('data/pdfs/exam.pdf')\n",
    "docs = loader.load_and_split()\n",
    "print(len(docs))\n",
    "print(docs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = docs[3].page_content\n",
    "# text = \"\"\"\n",
    "# Question 3 (Loss Functions, 17 points + 3 bonus points)\n",
    "# Equipped with cutting-edge Deep Learning knowledge, you are working with a biology lab.\n",
    "# Specifically, you're asked to build a classifier that predicts the animal type from a given\n",
    "# image into four ( ny= 4) classes: dog, cat, iguana, mouse . There's always exactly one\n",
    "# animal per image. You decide to use cross-entropy loss to train your network. Recall that\n",
    "# the cross-entropy (CE) loss for a single example is defined as follows:\n",
    "# LCE(^y;y) =nyP\n",
    "# i=1yilog ^yi\n",
    "# where ^y= (^y1;:::; ^yny)>represents the predicted probability distribution over the classes\n",
    "# andy= (y1;:::;yny)>is the ground truth vector, which is zero everywhere except for the\n",
    "# correct class (e.g. y= (1;0;0;0)>fordog, andy= (0;0;1;0)>foriguana ).\n",
    "# (a)(2 points) Suppose you're given an example image of an iguana. If the model correctly\n",
    "# predicts the resulting probability distribution as ^ y= (0:25;0:25;0:3;0:2)>, what is the\n",
    "# value of the cross-entropy loss? You can give an answer in terms of logarithms.\n",
    "# Solution:log 0:3\n",
    "# (b)(2 points) After some training, the model now incorrectly predicts mouse with distri-\n",
    "# butionh0:0;0:0;0:4;0:6ifor the same image. What is the new value of the cross-entropy\n",
    "# loss for this example?\n",
    "# Solution:log 0:4\n",
    "# (c)(2 points) Suprisingly, the model achieves lower loss for a misprediction than for a\n",
    "# correct prediction. Explain what implementation choices led to this phenomenon.\n",
    "# Solution: This is because our objective is to minimize CE-loss, rather than to\n",
    "# directly maximize accuracy. While CE-loss is a reasonable proxy to accuracy, there\n",
    "# is no guarantee that a lower CE loss will lead to higher accuracy.\n",
    "# (d)(2 points) Given your observation from question (c), you decide to train your neural\n",
    "# network with the accuracy as the objective instead of the cross-entropy loss. Is this a\n",
    "# good idea? Give one reason. Note that the accuracy of a model is defined as\n",
    "# Accuracy =(Number of correctly-classified examples)\n",
    "# (Total number of examples)\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = PromptTemplate.from_template(\n",
    "#     \"Read the following exam paper and extract the information requested in the schema for each question \\n\\n{exam_text}\\n\\n\\n\\n\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = create_structured_output(schema, llm, prompt)\n",
    "# input = prompt.format_prompt(exam_text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = runnable.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions_json = extract_question_answer_data(docs[3], schema, llm)\n",
    "# with open('data/exams.json', 'w') as f:\n",
    "#     f.write(questions_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    "    \"title\": \"Person\",\n",
    "    \"description\": \"Identifying information about a person.\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"title\": \"Name\", \"description\": \"The person's name\", \"type\": \"string\"},\n",
    "        \"age\": {\"title\": \"Age\", \"description\": \"The person's age\", \"type\": \"integer\"},\n",
    "        \"fav_food\": {\n",
    "            \"title\": \"Fav Food\",\n",
    "            \"description\": \"The person's favorite food\",\n",
    "            \"type\": \"string\",\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"You are a world class algorithm for extracting information in structured formats.\",\n",
    "#         ),\n",
    "#         (\n",
    "#             \"human\",\n",
    "#             \"Use the given format to extract information from the following input: {input}\",\n",
    "#         ),\n",
    "#         (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# runnable = create_structured_output_chain_runnable(json_schema, llm, prompt)\n",
    "# runnable.invoke({\"input\": \"Sally is 13\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aiprocessor(page_no, text, json_schema, llm=llm):\n",
    "    print(f\"\\n\\n..AI processing page {page_no}\")\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a world class algorithm for extracting questions and answers from exams, and putting them in a structured format.\n",
    "- User input is messy raw text extracted from a PDF page by PyPDF2.\n",
    "- The goal is to identify each question and extract the details cleanly as json.\n",
    "- Make sure you get every question and answer, and use the correct format.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"use the following schema to extract the questions and answers. \\n\\n\" + json_schema\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"raw pdf text; extract and format into json:\" + text\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    api_params = {\"model\": llm, \"messages\": messages, \"stream\": True}\n",
    "    try:\n",
    "        api_response = openai.ChatCompletion.create(**api_params)\n",
    "        reply = \"\"\n",
    "        for delta in api_response:\n",
    "            if not delta['choices'][0]['finish_reason']:\n",
    "                word = delta['choices'][0]['delta']['content']\n",
    "                reply += word\n",
    "                print(word, end =\"\")       \n",
    "        return reply\n",
    "    except Exception as err:\n",
    "        error_message = f\"API Error page {page_no}: {str(err)}\"\n",
    "        print(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your OpenAI API key and model\n",
    "# Create a list to store AI-processed text\n",
    "ai_processed_text_list = []\n",
    "\n",
    "# Open the PDF file in binary mode\n",
    "pdf_file = \"../data/pdfs/CS230_Midterm_spring_2018.pdf\"\n",
    "with open(pdf_file, 'rb') as pdf_file:\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "    # Iterate through each page and extract text\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        page_text = page.extract_text()\n",
    "\n",
    "        if len(page_text)>20:\n",
    "            # Dump unprocessed pages if desired\n",
    "            page_text_file = pdf_file.name + \"-extractedpage\" + str(page_num) + \".txt\"\n",
    "            with open(page_text_file, 'w', encoding='utf-8') as output_file:\n",
    "                output_file.write(page_text)\n",
    "\n",
    "            # Process with AI\n",
    "            ai_processed_text = aiprocessor(page_num, page_text, schema, model)\n",
    "\n",
    "            # Dump AI pages if desired\n",
    "            page_text_file = pdf_file.name + \"-AIpage\" + str(page_num) + \".txt\"\n",
    "            with open(page_text_file, 'w', encoding='utf-8') as output_file:\n",
    "                output_file.write(ai_processed_text)\n",
    "\n",
    "            # Append the AI-processed text to the list\n",
    "            ai_processed_text_list.append(ai_processed_text)\n",
    "\n",
    "# Combine all AI-processed text into a single string\n",
    "combined_text = \"\\n\".join(ai_processed_text_list)\n",
    "\n",
    "# Define the output text file name (same root name as the PDF)\n",
    "output_text_file = pdf_file.name + \"-AI-all.txt\"\n",
    "\n",
    "# Save the combined text into a .txt file\n",
    "with open(output_text_file, 'w', encoding='utf-8') as output_file:\n",
    "    output_file.write(combined_text)\n",
    "\n",
    "print(f\"AI-processed text saved to {output_text_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text = \"\\n\".join(ai_processed_text_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text_file = pdf_file.name + \"-AI-all.txt\"\n",
    "\n",
    "# Save the combined text into a .txt file\n",
    "with open(output_text_file, 'w', encoding='utf-8') as output_file:\n",
    "    output_file.write(combined_text)\n",
    "\n",
    "print(f\"AI-processed text saved to {output_text_file}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

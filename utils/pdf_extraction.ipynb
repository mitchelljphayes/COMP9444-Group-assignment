{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains.openai_functions import create_structured_output_runnable\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "import PyPDF2\n",
    "import glob\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from langchain.chains.openai_functions import (\n",
    "    create_openai_fn_chain,\n",
    "    create_structured_output_chain,\n",
    "    create_openai_fn_runnable,\n",
    "    create_structured_output_runnable,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# %load_ext dotenv\n",
    "# %dotenv ./.env\n",
    "config = load_dotenv('.env')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text(filename):\n",
    "    file = open(filename, 'rb')\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    text = ''\n",
    "    for page in range(len(reader.pages)):\n",
    "        page = reader.pages[page]\n",
    "        text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text_from_dir(dir):\n",
    "    text = ''\n",
    "    for filename in glob.glob(os.path.join(dir, '*.pdf')):\n",
    "        text += extract_pdf_text(filename)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = extract_pdf_text_from_dir(os.path.join('./data', 'pdfs'))\n",
    "with open('data/exams.txt', 'w') as f:\n",
    "    f.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_pdf_text('data/pdfs/exam.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.2, openai_api_key=OPENAI_API_KEY, model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"question_id\": {\"type\": \"string\"},\n",
    "        \"question\": {\"type\": \"string\"},\n",
    "        \"choices\": {\"type\": \"array\", \"option\": {\"type\": \"string\"}},\n",
    "        \"answer\": {\"type\": \"string\"},\n",
    "        \"question_type\": {\"type\": \"string\"},\n",
    "        \"topic\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"question_id\", \"question\", \"answer\", \"question_type\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_question_answer_data(doc, schema, llm):\n",
    "\n",
    "    \n",
    "    # input = prompt.format_prompt(exam_text=doc, schema=schema)\n",
    "    runnable = create_structured_output(schema, llm, prompt)\n",
    "    extract_output = runnable.invoke({'exam_text': \"what is the capital of France? \\n\\n Paris\"})\n",
    "    return extract_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "page_content='CS230\\nSolution: (iii)\\n(e)(1 point) Consider the model deﬁned in question (d) with parameters initialized with\\nzeros.W[1]denotes the weight matrix of the ﬁrst layer. You forward propagate a batch\\nof examples, and then backpropagate the gradients and update the parameters. Which\\nof the following statements is true?\\n(i) Entries of W[1]may be positive or negative\\n(ii) Entries of W[1]are all negative\\n(iii) Entries of W[1]are all positive\\n(iv) Entries of W[1]are all zeros\\nSolution: (i)\\n(f)(2 points) Consider the layers landl−1 in a fully connected neural network:\\nThe forward propagation equations for these layers are:\\nz[l−1]=W[l−1]a[l−2]+b[l−1]\\na[l−1]=g[l−1](z[l−1])\\nz[l]=W[l]a[l−1]+b[l]\\na[l]=g[l](z[l])\\nWhich of the following propositions is true? Xavier initialization ensures that :\\n(i)Var(W[l−1]) is the same as Var(W[l]).\\n(ii)Var(b[l]) is the same as Var(b[l−1]).\\n(iii)Var(a[l]) is the same as Var(a[l−1]), at the end of training.\\n(iv)Var(a[l]) is the same as Var(a[l−1]), at the beginning of training.\\nSolution: (iv)\\n4' metadata={'source': 'data/pdfs/exam.pdf', 'page': 3}\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader('data/pdfs/exam.pdf')\n",
    "docs = loader.load_and_split()\n",
    "print(len(docs))\n",
    "print(docs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = docs[3].page_content\n",
    "text = \"\"\"\n",
    "Question 3 (Loss Functions, 17 points + 3 bonus points)\n",
    "Equipped with cutting-edge Deep Learning knowledge, you are working with a biology lab.\n",
    "Specifically, you're asked to build a classifier that predicts the animal type from a given\n",
    "image into four ( ny= 4) classes: dog, cat, iguana, mouse . There's always exactly one\n",
    "animal per image. You decide to use cross-entropy loss to train your network. Recall that\n",
    "the cross-entropy (CE) loss for a single example is defined as follows:\n",
    "LCE(^y;y) =nyP\n",
    "i=1yilog ^yi\n",
    "where ^y= (^y1;:::; ^yny)>represents the predicted probability distribution over the classes\n",
    "andy= (y1;:::;yny)>is the ground truth vector, which is zero everywhere except for the\n",
    "correct class (e.g. y= (1;0;0;0)>fordog, andy= (0;0;1;0)>foriguana ).\n",
    "(a)(2 points) Suppose you're given an example image of an iguana. If the model correctly\n",
    "predicts the resulting probability distribution as ^ y= (0:25;0:25;0:3;0:2)>, what is the\n",
    "value of the cross-entropy loss? You can give an answer in terms of logarithms.\n",
    "Solution:log 0:3\n",
    "(b)(2 points) After some training, the model now incorrectly predicts mouse with distri-\n",
    "butionh0:0;0:0;0:4;0:6ifor the same image. What is the new value of the cross-entropy\n",
    "loss for this example?\n",
    "Solution:log 0:4\n",
    "(c)(2 points) Suprisingly, the model achieves lower loss for a misprediction than for a\n",
    "correct prediction. Explain what implementation choices led to this phenomenon.\n",
    "Solution: This is because our objective is to minimize CE-loss, rather than to\n",
    "directly maximize accuracy. While CE-loss is a reasonable proxy to accuracy, there\n",
    "is no guarantee that a lower CE loss will lead to higher accuracy.\n",
    "(d)(2 points) Given your observation from question (c), you decide to train your neural\n",
    "network with the accuracy as the objective instead of the cross-entropy loss. Is this a\n",
    "good idea? Give one reason. Note that the accuracy of a model is defined as\n",
    "Accuracy =(Number of correctly-classified examples)\n",
    "(Total number of examples)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = PromptTemplate.from_template(\n",
    "#     \"Read the following exam paper and extract the information requested in the schema for each question \\n\\n{exam_text}\\n\\n\\n\\n\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = create_structured_output(schema, llm, prompt)\n",
    "# input = prompt.format_prompt(exam_text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = runnable.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions_json = extract_question_answer_data(docs[3], schema, llm)\n",
    "# with open('data/exams.json', 'w') as f:\n",
    "#     f.write(questions_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    "    \"title\": \"Person\",\n",
    "    \"description\": \"Identifying information about a person.\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"title\": \"Name\", \"description\": \"The person's name\", \"type\": \"string\"},\n",
    "        \"age\": {\"title\": \"Age\", \"description\": \"The person's age\", \"type\": \"integer\"},\n",
    "        \"fav_food\": {\n",
    "            \"title\": \"Fav Food\",\n",
    "            \"description\": \"The person's favorite food\",\n",
    "            \"type\": \"string\",\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Unrecognized request arguments supplied: function_call, functions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/mjp/Documents/Study/UNSW/23T3-9444/group-assignment/pdf_extraction.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mjp/Documents/Study/UNSW/23T3-9444/group-assignment/pdf_extraction.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m prompt \u001b[39m=\u001b[39m ChatPromptTemplate\u001b[39m.\u001b[39mfrom_messages(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mjp/Documents/Study/UNSW/23T3-9444/group-assignment/pdf_extraction.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     [\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mjp/Documents/Study/UNSW/23T3-9444/group-assignment/pdf_extraction.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mjp/Documents/Study/UNSW/23T3-9444/group-assignment/pdf_extraction.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mjp/Documents/Study/UNSW/23T3-9444/group-assignment/pdf_extraction.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mjp/Documents/Study/UNSW/23T3-9444/group-assignment/pdf_extraction.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m runnable \u001b[39m=\u001b[39m create_structured_output_runnable(json_schema, llm, prompt)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mjp/Documents/Study/UNSW/23T3-9444/group-assignment/pdf_extraction.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m runnable\u001b[39m.\u001b[39;49minvoke({\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mSally is 13\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/langchain/schema/runnable/base.py:1153\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1152\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 1153\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   1154\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   1155\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1156\u001b[0m             patch_config(\n\u001b[1;32m   1157\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1158\u001b[0m             ),\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[1;32m   1160\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/langchain/schema/runnable/base.py:2505\u001b[0m, in \u001b[0;36mRunnableBinding.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2499\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m   2500\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2501\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   2502\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2503\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2504\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Output:\n\u001b[0;32m-> 2505\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   2506\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   2507\u001b[0m         merge_configs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig, config),\n\u001b[1;32m   2508\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs},\n\u001b[1;32m   2509\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/langchain/llms/base.py:229\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    220\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    221\u001b[0m     \u001b[39minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    226\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    227\u001b[0m     config \u001b[39m=\u001b[39m config \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    228\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 229\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    230\u001b[0m             [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m)],\n\u001b[1;32m    231\u001b[0m             stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    232\u001b[0m             callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    233\u001b[0m             tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    234\u001b[0m             metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    235\u001b[0m             run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    236\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    237\u001b[0m         )\n\u001b[1;32m    238\u001b[0m         \u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    239\u001b[0m         \u001b[39m.\u001b[39mtext\n\u001b[1;32m    240\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/langchain/llms/base.py:501\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    494\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    495\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    499\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    500\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 501\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/langchain/llms/base.py:650\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    636\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    637\u001b[0m         )\n\u001b[1;32m    638\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[1;32m    639\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    640\u001b[0m             dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    648\u001b[0m         )\n\u001b[1;32m    649\u001b[0m     ]\n\u001b[0;32m--> 650\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    651\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    652\u001b[0m     )\n\u001b[1;32m    653\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/langchain/llms/base.py:538\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[1;32m    537\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 538\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    539\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m    540\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/langchain/llms/base.py:525\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    516\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    517\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    522\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    523\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 525\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    526\u001b[0m                 prompts,\n\u001b[1;32m    527\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    528\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    529\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    530\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    531\u001b[0m             )\n\u001b[1;32m    532\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    533\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    534\u001b[0m         )\n\u001b[1;32m    535\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/langchain/llms/openai.py:401\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m     choices\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    390\u001b[0m         {\n\u001b[1;32m    391\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: generation\u001b[39m.\u001b[39mtext,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    398\u001b[0m         }\n\u001b[1;32m    399\u001b[0m     )\n\u001b[1;32m    400\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m     response \u001b[39m=\u001b[39m completion_with_retry(\n\u001b[1;32m    402\u001b[0m         \u001b[39mself\u001b[39;49m, prompt\u001b[39m=\u001b[39;49m_prompts, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m    403\u001b[0m     )\n\u001b[1;32m    404\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    405\u001b[0m     update_token_usage(_keys, response, token_usage)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/langchain/llms/openai.py:115\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    113\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 115\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/langchain/llms/openai.py:113\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[1;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    715\u001b[0m         ),\n\u001b[1;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/group-assignment-f09OljWU/lib/python3.11/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: Unrecognized request arguments supplied: function_call, functions"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a world class algorithm for extracting information in structured formats.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following input: {input}\",\n",
    "        ),\n",
    "        (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "runnable = create_structured_output_runnable(json_schema, llm, prompt)\n",
    "runnable.invoke({\"input\": \"Sally is 13\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
